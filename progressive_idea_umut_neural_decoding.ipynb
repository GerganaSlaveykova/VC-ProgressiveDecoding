{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Decoding - Latent prediction - Progressive idea - Umut\n",
        "##Written by Gergana Slaveykova s1070004\n",
        "##Radboud University- B3 Thesis project"
      ],
      "metadata": {
        "id": "RQMEm4iGCIZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "fnu65XIdH_DD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount Google Drive to acess data and storing purposes\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ckv1M6syntF",
        "outputId": "6d0a595d-09ba-401c-c6bd-b9cc5f7041c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Installs\n",
        "! pip install mxnet\n",
        "! pip install nilearn\n",
        "! pip install nibabel\n",
        "!pip install git+https://github.com/nipy/nipy.git\n"
      ],
      "metadata": {
        "id": "euTUMwFeyW-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from nipy.modalities.fmri.experimental_paradigm import load_paradigm_from_csv_file\n",
        "from nipy.modalities.fmri.design_matrix import make_dmtx\n",
        "from nipy.labs.viz import plot_map, cm\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "from types import ModuleType\n",
        "from typing import Tuple, Union\n",
        "\n",
        "from nilearn import masking, plotting\n",
        "from PIL import Image\n",
        "from scipy.stats import t, zscore\n",
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import h5py\n",
        "import PIL.Image\n",
        "from scipy import sparse, stats\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from numpy.linalg import svd\n",
        "import time\n",
        "from scipy import signal"
      ],
      "metadata": {
        "id": "3qLAtrMSzmHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structure\n"
      ],
      "metadata": {
        "id": "Qrfc52G3xpEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Regions of interest\n",
        "rois = {\n",
        "        'V1' : 'ROI_V1 = 1',\n",
        "        'V2' : 'ROI_V2 = 1',\n",
        "        'V3' : 'ROI_V3 = 1',\n",
        "        'V4' : 'ROI_V4 = 1',\n",
        "        'LOC' : 'ROI_LOC = 1',\n",
        "        'FFA' : 'ROI_FFA = 1',\n",
        "        'PPA' : 'ROI_PPA = 1'}\n",
        "\n",
        "rois.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YeGX6DCuEw-",
        "outputId": "36c72178-f76d-4048-8d53-c9535acd3b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['V1', 'V2', 'V3', 'V4', 'LOC', 'FFA', 'PPA'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load brain data\n",
        "x_tr = []\n",
        "x_te = []\n",
        "for roi_index, roi in enumerate(rois):\n",
        "    _roi = np.load(f\"/content/drive/MyDrive/GOD-NEW-3p/my_experiment_{roi}_hyperaligned.npy\")              # load in roi, all voxels, you want to select a mask\n",
        "    x_tr.append(_roi[:1200])               # mean over participants, first 1200 are training set, only use mask voxels\n",
        "    x_te.append(_roi[1200:1250])          # mean over participants, 1200:1250 are test set, only use mask voxels\n"
      ],
      "metadata": {
        "id": "K09-piC9tF7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#oad latents of images\n",
        "w_te= np.load(\"/content/drive/MyDrive/GOD-NEW-3p/latents/t_te_best.npy\")\n",
        "w_tr= np.load(\"/content/drive/MyDrive/GOD-NEW-3p/latents/t_tr_best.npy\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FmQmIhQiucnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load indices for filtering\n",
        "file_path = \"/content/drive/MyDrive/GOD-NEW-3p/Neural-DecodingPartProgresive/indeces_filtered_clipped3.dat\"\n",
        "importantind = np.load(file_path,allow_pickle=True)\n"
      ],
      "metadata": {
        "id": "9Jx1EqTBibiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def z_score(x_tr,x_te_pt):\n",
        "  # Z-score normalization\n",
        "  # Calculate mean and standard deviation on training data\n",
        "  norm_mean_x = np.mean(x_tr, axis=0)\n",
        "  norm_std_x = np.std(x_tr, axis=0, ddof=1)\n",
        "  # Avoid division by zero\n",
        "  norm_std_x[norm_std_x == 0] = 1\n",
        "\n",
        "  # Normalization\n",
        "  x_tr_normalized = (x_tr - norm_mean_x) / norm_std_x\n",
        "  x_te_pt_normalized = (x_te_pt - norm_mean_x) / norm_std_x\n",
        "\n",
        "  # Z-scoring the whole dataset\n",
        "  #x_whole_normalized = (x - np.mean(x, axis=0)) / np.std(x, axis=0, ddof=1)\n",
        "\n",
        "  return x_tr_normalized,x_te_pt_normalized"
      ],
      "metadata": {
        "id": "xwDtBts8smqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The code bellow can be optimised and without repetitions with a function. I decided that for me it is easier to look at each region separately."
      ],
      "metadata": {
        "id": "znXMbSLXHKh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LOC"
      ],
      "metadata": {
        "id": "jl9x4DiSFmVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predic LOC\n",
        "model_loc = LinearRegression().fit(x_tr[4], w_tr)\n",
        "y_te_loc = model_loc.predict(x_te[4]) # putting as input -> LOC activity\n",
        "y_tr_loc = model_loc.predict(x_tr[4])\n",
        "y_te_loc.shape, y_tr_loc.shape\n",
        "\n",
        "#y_tr_loc,y_te_loc=z_score(y_tr_loc,y_te_loc)\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/GOD-NEW-3p/Plain-Z-scored/\"\n",
        "\n",
        "#Store latents\n",
        "with open(f'{file_path}progressive_y_te_loc.npy', 'wb') as fp:\n",
        "            pickle.dump(y_te_loc, fp)"
      ],
      "metadata": {
        "id": "pJrOYhZ_u8x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#V4"
      ],
      "metadata": {
        "id": "-M_YL3saGF3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The concatenation of the predicted latents with the next region\n",
        "x_tr_v4 = np.concatenate((x_tr[3], y_tr_loc), axis=1)\n",
        "x_te_v4 = np.concatenate((x_te[3], y_te_loc), axis=1)\n",
        "x_tr_v4.shape, x_te_v4.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqwqPYlFu-WA",
        "outputId": "099bbb82-d18f-4136-9226-f019db6e9fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1200, 1795), (50, 1795))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train a model and predict V4\n",
        "model_v4 = LinearRegression().fit(x_tr_v4, w_tr)\n",
        "y_te_v4 = model_v4.predict(x_te_v4) # putting as input -> V4 activity\n",
        "y_tr_v4 = model_v4.predict(x_tr_v4)\n",
        "y_te_v4.shape, y_tr_v4.shape\n",
        "\n",
        "#y_tr_v4,y_te_v4=z_score(y_tr_v4,y_te_v4)\n",
        "\n",
        "#Store latents\n",
        "with open(f'{file_path}progressive_y_te_v4.npy', 'wb') as fp:\n",
        "            pickle.dump(y_te_v4, fp)"
      ],
      "metadata": {
        "id": "4HUykf8VvDFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#V3"
      ],
      "metadata": {
        "id": "cwir-GrZvYVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The concatenation of the predicted latents with the next region\n",
        "x_tr_v3 = np.concatenate((x_tr[2], y_tr_v4), axis=1)\n",
        "x_te_v3 = np.concatenate((x_te[2], y_te_v4), axis=1)\n",
        "x_tr_v3.shape, x_te_v3.shape\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scwdm6SKvdhJ",
        "outputId": "3389e71d-5e0f-42f0-f307-f5bdb5b9156c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1200, 2570), (50, 2570))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train a model and predict V3\n",
        "model_v3 = LinearRegression().fit(x_tr_v3, w_tr)\n",
        "y_te_v3 = model_v3.predict(x_te_v3) # putting as input -> V4 activity\n",
        "y_tr_v3 = model_v3.predict(x_tr_v3)\n",
        "y_te_v3.shape, y_tr_v3.shape\n",
        "\n",
        "#y_tr_v3,y_te_v3=z_score(y_tr_v3,y_te_v3)\n",
        "\n",
        "#Store latents\n",
        "with open(f'{file_path}progressive_y_te_v3.npy', 'wb') as fp:\n",
        "            pickle.dump(y_te_v3, fp)"
      ],
      "metadata": {
        "id": "iaK_0oPxv4AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#V2\n"
      ],
      "metadata": {
        "id": "WcgK5nQdvZQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The concatenation of the predicted latents with the next region\n",
        "x_tr_v2 = np.concatenate((x_tr[1], y_tr_v3), axis=1)\n",
        "x_te_v2 = np.concatenate((x_te[1], y_te_v3), axis=1)\n",
        "x_tr_v2.shape, x_te_v2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fmVEcA9wU9_",
        "outputId": "9ab9c3fb-a3b0-493f-fdcd-bb1c17b16198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1200, 3199), (50, 3199))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train a model and predict V2\n",
        "model_v2 = LinearRegression().fit(x_tr_v2, w_tr)\n",
        "y_te_v2 = model_v2.predict(x_te_v2)\n",
        "y_tr_v2 = model_v2.predict(x_tr_v2)\n",
        "y_te_v2.shape, y_tr_v2.shape\n",
        "\n",
        "\n",
        "#y_tr_v2,y_te_v2=z_score(y_tr_v2,y_te_v2)\n",
        "\n",
        "#Store latents\n",
        "with open(f'{file_path}progressive_y_te_v2.npy', 'wb') as fp:\n",
        "            pickle.dump(y_te_v2, fp)"
      ],
      "metadata": {
        "id": "GN1fiKS_wh3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#V1"
      ],
      "metadata": {
        "id": "NI4hkqvXwvOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The concatenation of the predicted latents with the next region\n",
        "x_tr_v1 = np.concatenate((x_tr[0], y_tr_v2), axis=1)\n",
        "x_te_v1 = np.concatenate((x_te[0], y_te_v2), axis=1)\n",
        "x_tr_v1.shape, x_te_v1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPgX1DnEwt9D",
        "outputId": "d6195016-ec85-4ad1-aada-427695368fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1200, 3033), (50, 3033))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train a model and predict V1\n",
        "model_v1 = LinearRegression().fit(x_tr_v1, w_tr)\n",
        "y_te_v1 = model_v1.predict(x_te_v1)\n",
        "y_tr_v1 = model_v1.predict(x_tr_v1)\n",
        "y_te_v1.shape, y_tr_v1.shape\n",
        "\n",
        "#y_tr_v1,y_te_v1=z_score(y_tr_v1,y_te_v1)\n",
        "\n",
        "#train a model and predict V1\n",
        "with open(f'{file_path}progressive_y_te_v1.npy', 'wb') as fp:\n",
        "            pickle.dump(y_te_v1, fp)"
      ],
      "metadata": {
        "id": "GSlYqGeLvbAF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
